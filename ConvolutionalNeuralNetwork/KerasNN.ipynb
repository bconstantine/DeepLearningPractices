{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#The following code is from Andrew Ng Deeplearning AI\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import math\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Code is from Andrew Ng Kt.utils\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example is from Andrew Ng Course\n",
    "```python\n",
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: The height, width and channels as a tuple.  \n",
    "        Note that this does not include the 'batch' as a dimension.\n",
    "        If you have a batch like 'X_train', \n",
    "        then you can provide the input_shape using\n",
    "        X_train.shape[1:]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    \n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The double parentheses mean that they are actually an object. For example:\n",
    "```python\n",
    "X = ZeroPadding2D((3,3))(X_input)\n",
    "```\n",
    "\n",
    "is equivalent to this:\n",
    "```python\n",
    "ZeroPaddingObject = ZeroPadding2D((3,3)) #This one makes an object of zero padding 2d through constructor\n",
    "X = ZeroPaddingObject(X_input) #This will call the __call__ function defined inside ZeroPadding2D class\n",
    "```\n",
    "\n",
    "Pay attention also that in Keras, we usually overwrite the same variable again and again (except the first one for the xInput / X_input), rather than in TensorFlow where we create different name for each operation. By using the same variable again and again, it signalizes that the layers are stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for practice of Andrew Ng Convolutional Neural Network course week 2 of Keras Toutorial\n",
    "def HappyModel(inputShape):\n",
    "    \"\"\"Make a keras model for the happy problem\n",
    "    \n",
    "    Arguments:\n",
    "    inputShape = the shape of the input (not included with datasets amount, just (nH,nW,nC) as a tuple)\n",
    "                to discard the dataset amount, use X_train.shape[1:]\n",
    "                \n",
    "    Return:\n",
    "    model = a Model() instance in Keras\"\"\"\n",
    "    \n",
    "    XInput = Input(inputShape)\n",
    "    \n",
    "    X = ZeroPadding2D((3,3))(XInput) #This make a padding in amount of nH, nW. So it pads each height and weight with 3\n",
    "    \n",
    "    #Making a convolution layer. Conv2D is used to create a convolution layer for 2d objects such as image\n",
    "    #Even though the image itself will be broken into volume (RGB for example), Conv2D will understand it as a volume\n",
    "    #On the other hand, Conv3D is used when there is time variable affects the x dataset\n",
    "    #32 means the output filter, so the result nC of the convolution will be 32\n",
    "    #(7,7) means it will create a filter size with 7,7 size.\n",
    "    #Strides = a tuple of two ints for the amount of stride in nH and nW\n",
    "    #name = save a name inside the Keras memory\n",
    "    X = Conv2D(32,(7,7),strides = (1,1), name = 'conv0')(X)\n",
    "    \n",
    "    #Normalize the data with the BatchNormalization. Since we want to normalize the number based on the mean of\n",
    "    #every channel (we make sure that for every channel, the number should be between 0 and 1 and its standard\n",
    "    #deviation is 0). That is why, we make sure that we normalize it for every channel.\n",
    "    #Basically, choose the axis that represents the channel, since we have form of (datasets, height, width, channel)\n",
    "    #We use the axis = 3 since channel is in the fourth shape\n",
    "    X = BatchNormalization(axis = 3, name = \"bn0\")(X)\n",
    "    \n",
    "    #After we normalize based on the mean and standard deviation of each respective channel, now it is time for us to\n",
    "    #Do activation layer of relu\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #After activation, do pooling = MaxPooling2D. We use 2D since the input doesn't take time as argument\n",
    "    #No need to put the output nC since the number of nC will be the same as the input\n",
    "    #The tuple means for the size of the filter, in size of (nH, nW)\n",
    "    X = MaxPooling2D((2,2), name = \"maxPool\")(X)\n",
    "    \n",
    "    #The next layer is used for flattening the resulted X, preparing it for fully connected layer\n",
    "    #If the input is in shape of (m,nH,nW,nC), it will become (m, nH*nW*nC) after flattened\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    #Make the final fully connected layer by making a Dense Layer in Keras\n",
    "    #The 1 means the result node that we want, the activation for the final activation\n",
    "    X = Dense(1, activation = \"sigmoid\", name = \"fc\")(X)\n",
    "    \n",
    "    #Now that since everyting is already in set, we can create the model directly by using Model()\n",
    "    #Set the \"inputs = \" parameters of the model with the \"XInput\" Tensor\n",
    "    #Set the \"outputs = \" parameters of the model with the \"X\" Tensor\n",
    "    model = Model(inputs = XInput, outputs = X, name = \"HappyModel\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explanation is from Andrew Ng Course. \n",
    "To train and test this model, there are four steps in Keras:\n",
    "1. Create the model by calling the function above  \n",
    "2. Compile the model by calling `model.compile(optimizer = \"...\", loss = \"...\", metrics = [\"accuracy\"])`  \n",
    "3. Train the model on train data by calling `model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)`  \n",
    "4. Test the model on test data by calling `model.evaluate(x = ..., y = ...)`  \n",
    "\n",
    "Refer to the official [Keras documentation](https://keras.io/models/model/).\n",
    "\n",
    "optimizer = 'adam', 'sgd'\n",
    "\n",
    "loss = 'binary_crossentropy', 'categorical_crossentropy' (should separate array for each category)\n",
    "\n",
    "Calling .fit() multiple times will make the model retrain rather thn reinitializing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/40\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 3.5136 - accuracy: 0.5483\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.5500 - accuracy: 0.5650\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 1.1623 - accuracy: 0.6083\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.5651 - accuracy: 0.8033\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.4107 - accuracy: 0.8133\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.3683 - accuracy: 0.8400\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.2407 - accuracy: 0.9083\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.1671 - accuracy: 0.9317\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.1560 - accuracy: 0.9417\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.1285 - accuracy: 0.9567\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.1279 - accuracy: 0.9617\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1144 - accuracy: 0.9567\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.1037 - accuracy: 0.9700\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 8s 14ms/step - loss: 0.0974 - accuracy: 0.9767\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0859 - accuracy: 0.9817\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0818 - accuracy: 0.9783\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0746 - accuracy: 0.9783\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0741 - accuracy: 0.9817\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0767 - accuracy: 0.9817\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0692 - accuracy: 0.9800\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0649 - accuracy: 0.9817\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0629 - accuracy: 0.9850\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0590 - accuracy: 0.9850\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.0536 - accuracy: 0.9850\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0517 - accuracy: 0.9867\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0479 - accuracy: 0.9917\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0523 - accuracy: 0.9883\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0459 - accuracy: 0.9933\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.0466 - accuracy: 0.9917\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0451 - accuracy: 0.9833\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0406 - accuracy: 0.9900\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0372 - accuracy: 0.9917\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.0328 - accuracy: 0.9900\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0338 - accuracy: 0.9900\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0307 - accuracy: 0.9900\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0346 - accuracy: 0.9900\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 7s 12ms/step - loss: 0.0306 - accuracy: 0.9933\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0309 - accuracy: 0.9933\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 8s 13ms/step - loss: 0.0260 - accuracy: 0.9950\n",
      "150/150 [==============================] - 1s 4ms/step\n",
      "Loss result = 0.25179621974627175\n",
      "Test Accuracy = 0.9399999976158142\n"
     ]
    }
   ],
   "source": [
    "#Create model\n",
    "model = HappyModel(X_train.shape[1:])\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.fit(x = X_train, y = Y_train, epochs = 40, batch_size = 128)\n",
    "preds = model.evaluate(x=X_test, y = Y_test)\n",
    "print(f\"Loss result = {preds[0]}\")\n",
    "print(f\"Test Accuracy = {preds[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips to increase accuracy:\n",
    "- Use blocks of Conv->BatchNorm->ReLU so that the height and the width can shrink, while the number of channels quite large\n",
    "- Use MAXPOOL after suc block, it will help us lower the dimension in height and width\n",
    "- For memory issues, lower the batch_size (to 12 perhaps)\n",
    "- Run more epochs until te train accuracy no longer improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagePath = \"images/NotSmile.jpg\"\n",
    "img = image.load_img(imagePath,target_size = (64,64)) #from keras.preprocessing\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img) #convert to numpy array\n",
    "x = np.expand_dims(x,axis = 0) #added one more dimension for the x on index 0\n",
    "x = preprocess_input(x) #from keras.applications.imagenet_utils (preprocess the input with imagenet rules)\n",
    "\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HappyModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "maxPool (MaxPooling2D)       (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 37,633\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1925\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1926\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1927\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1932\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1933\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1934\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot.exe\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-97dea27b0500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"HappyModel.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[0;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[1;32m--> 240\u001b[1;33m                        expand_nested, dpi)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         raise OSError(\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file = \"HappyModel.png\")\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
