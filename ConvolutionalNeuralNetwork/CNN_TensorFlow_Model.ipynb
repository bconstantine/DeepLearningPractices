{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#The following code is from Andrew Ng CNN Course\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    #C - number of rows (here it will be the number of category)\n",
    "    #Y - the category of the answer, will be in 2,1,2,3... and so on.\n",
    "    #reshape - 1 means that it will make everything into 1d array\n",
    "    #np.eye makes 2d array that set 1 for each diagonal, and set 0 otherwise\n",
    "    #Using the [2], will generate 0 0 1 .....\n",
    "    #Using the transpose we can make sure to make an array that has row for category and column for datapoints\n",
    "    Y = (np.eye(C)[Y.reshape(-1)]).T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "# Example of a picture\n",
    "index = 6\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig / 255\n",
    "X_test = X_test_orig / 255\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPlaceholders(nH0, nW0, nC0, nY):\n",
    "    \"\"\"\n",
    "    Intent: This function will create the required placeholder for input and output when used inside the session\n",
    "    \n",
    "    Pre:\n",
    "    nH0 = the number of the height for the pixel image input(also called layer 0)\n",
    "    nW0 = the number of the width for the pixel image input(also called layer 0)\n",
    "    nC0 = the number of the channel for the pixel image input(also called layer 0)\n",
    "    nY = the number of the classes for the output\n",
    "    \n",
    "    Post:\n",
    "    X = placeholder for the input, the first shape is set as None because we don't know the number of datapoints\n",
    "    Y = placeholder for the output, the first shape is set as None because we don't know the number of the datapoints\"\"\"\n",
    "    X = tf.placeholder(shape = [None, nH0, nW0, nC0], dtype = \"float\", name = \"X\")\n",
    "    Y = tf.placeholder(shape = [None,nY], dtype = \"float\", name = \"Y\")\n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Y = Tensor(\"Y:0\", shape=(?, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = createPlaceholders(64, 64, 3, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters(parametersDims):\n",
    "    \"\"\"Initialize the w with the tf.contrib.xavier_initializer()\n",
    "    \n",
    "    Pre:\n",
    "    parametersDims: 2d array: each of the 1d array has (nH, nW,nC_prev, nC)\n",
    "    \n",
    "    Post:\n",
    "    parameters: dictionary of tensorflow variable that has been made\"\"\"\n",
    "    tf.set_random_seed(1)   \n",
    "    parameters = {}\n",
    "    for i in range(len(parametersDims)):\n",
    "        parameters[f\"W{i+1}\"] = tf.get_variable(f\"W{i+1}\", parametersDims[i], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1[1,1,1] = \n",
      "[ 0.00131723  0.1417614  -0.04434952  0.09197326  0.14984085 -0.03514394\n",
      " -0.06847463  0.05245192]\n",
      "W1.shape: (4, 4, 3, 8)\n",
      "\n",
      "\n",
      "W2[1,1,1] = \n",
      "[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
      " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
      " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n",
      "W2.shape: (2, 2, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "parametersDims = [[4,4,3,8], [2,2,8,16]]\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initializeParameters(parametersDims)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1[1,1,1] = \\n\" + str(parameters[\"W1\"].eval()[1,1,1]))\n",
    "    print(\"W1.shape: \" + str(parameters[\"W1\"].shape))\n",
    "    print(\"\\n\")\n",
    "    print(\"W2[1,1,1] = \\n\" + str(parameters[\"W2\"].eval()[1,1,1]))\n",
    "    print(\"W2.shape: \" + str(parameters[\"W2\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Forward propagation\n",
    "\n",
    "In TensorFlow, there are built-in functions that implement the convolution steps for you.\n",
    "\n",
    "- **tf.nn.conv2d(X,W, strides = [1,s,s,1], padding = 'SAME'):** given an input $X$ and a group of filters $W$, this function convolves $W$'s filters on X. The third parameter ([1,s,s,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). Normally, you'll choose a stride of 1 for the number of examples (the first value) and for the channels (the fourth value), which is why we wrote the value as `[1,s,s,1]`. You can read the full documentation on [conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d).\n",
    "\n",
    "- **tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = 'SAME'):** given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window.  For max pooling, we usually operate on a single example at a time and a single channel at a time.  So the first and fourth value in `[1,f,f,1]` are both 1.  You can read the full documentation on [max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool).\n",
    "\n",
    "- **tf.nn.relu(Z):** computes the elementwise ReLU of Z (which can be any shape). You can read the full documentation on [relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu).\n",
    "\n",
    "- **tf.contrib.layers.flatten(P)**: given a tensor \"P\", this function takes each training (or test) example in the batch and flattens it into a 1D vector.  \n",
    "    * If a tensor P has the shape (m,h,w,c), where m is the number of examples (the batch size), it returns a flattened tensor with shape (batch_size, k), where $k=h \\times w \\times c$.  \"k\" equals the product of all the dimension sizes other than the first dimension.\n",
    "    * For example, given a tensor with dimensions [100,2,3,4], it flattens the tensor to be of shape [100, 24], where 24 = 2 * 3 * 4.  You can read the full documentation on [flatten](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten).\n",
    "\n",
    "- **tf.contrib.layers.fully_connected(F, num_outputs):** given the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation on [full_connected](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected).\n",
    "\n",
    "In the last function above (`tf.contrib.layers.fully_connected`), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters.\n",
    "\n",
    "\n",
    "#### Window, kernel, filter\n",
    "The words \"window\", \"kernel\", and \"filter\" are used to refer to the same thing.  This is why the parameter `ksize` refers to \"kernel size\", and we use `(f,f)` to refer to the filter size.  Both \"kernel\" and \"filter\" refer to the \"window.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagation(X,parameters, strideCNN, strideMaxpool, strideMaxF, outputNumber):\n",
    "    \"\"\"This function can execute forward propagation of CNN, and ended by fully connected layers.\n",
    "    \n",
    "    parameters:\n",
    "    X = placeholder for input in shape of (input size, numOfExamples)\n",
    "    parameters = dictionary tensor initialized before for each filter, with keys of W{number}\n",
    "    strideCNN = stride from layer 1 until layer L of CNN\n",
    "    strideMaxpool = stride from layer 1 until layer L of Maxpool\n",
    "    strideMaxF = f size for max pooling\n",
    "    outputNumber = number of category for the output\n",
    "    \n",
    "    return: \n",
    "    ZL = the ZL of last layer, which is after the fully connected and ready for the output\"\"\"\n",
    "    \n",
    "    L = len(parameters) #return number layer, for iteration of CNN\n",
    "    cache = {} #the cache for Z and A\n",
    "    \n",
    "    cache[\"P0\"] = X #let's just set X to P0 since we end every CNN process in P\n",
    "    assert strideMaxF.shape == strideMaxpool.shape\n",
    "    for i in range(L):\n",
    "        cache[f\"Z{i+1}\"] = tf.nn.conv2d(cache[f\"P{i}\"], parameters[f\"W{i+1}\"], strides = [1, strideCNN[i], strideCNN[i], 1], padding = \"SAME\")\n",
    "        cache[f\"A{i+1}\"] = tf.nn.relu(cache[f\"Z{i+1}\"])\n",
    "        cache[f\"P{i+1}\"] = tf.nn.max_pool(cache[f\"A{i+1}\"], ksize = [1,strideMaxF[i], strideMaxF[i], 1], strides = [1,strideMaxpool[i], strideMaxpool[i], 1], padding = \"SAME\")\n",
    "    \n",
    "    #Flatting the layer\n",
    "    F1 = tf.contrib.layers.flatten(cache[f\"P{L}\"])\n",
    "    #use fully connected layer, usu tf.contrib.fully_connected(). leave the activation as none, we don't want to put softmax here, since the\n",
    "    #softmax will be included when counting the loss function\n",
    "    cache[f\"ZFinal\"] = tf.contrib.layers.fully_connected(F1, outputNumber, activation_fn = None)\n",
    "    return cache[f\"ZFinal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792A887E88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792A887E88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792A887E88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792A887E88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A864108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A864108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A864108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A864108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Z3 = \n",
      "[[ 1.4416982  -0.24909668  5.4504995  -0.2618962  -0.20669872  1.3654671 ]\n",
      " [ 1.4070847  -0.02573182  5.08928    -0.4866991  -0.4094069   1.2624853 ]]\n"
     ]
    }
   ],
   "source": [
    "#This test case is from Andrew Ng Example\n",
    "tf.reset_default_graph()\n",
    "parametersDims = [[4,4,3,8], [2,2,8,16]]\n",
    "strideCNN = [1,1] #stride from layer 1 until layer L of CNN, for now set to 1 and 1 only\n",
    "strideMaxpool = np.array([8,4]) #stride from layer 1 until layer L of Maxpool, for now set to 8 and 4\n",
    "strideMaxF = np.array([8,4]) #F size for max pooling\n",
    "outputNumber = 6 #for now since we have 6 class\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = createPlaceholders(64, 64, 3, 6)\n",
    "    parameters = initializeParameters(parametersDims)\n",
    "    Z3 = forwardPropagation(X, parameters, strideCNN, strideMaxpool, strideMaxF, outputNumber)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z3, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,6)})\n",
    "    print(\"Z3 = \\n\" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(Z3, Y):\n",
    "    \"\"\"Compute the cost with softmax initializer\n",
    "    \n",
    "    Input: \n",
    "    Z3 = result of the last layer in the shape of (m, categoryNumber)\n",
    "    Y = label of the correct output, same shape of Z3\"\"\"\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792944F508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792944F508>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792944F508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002792944F508>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002791E4DB888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002791E4DB888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002791E4DB888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002791E4DB888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "cost = 4.664871\n"
     ]
    }
   ],
   "source": [
    "#This testcase is from Andrew Ng\n",
    "tf.reset_default_graph()\n",
    "parametersDims = [[4,4,3,8], [2,2,8,16]]\n",
    "strideCNN = [1,1] #stride from layer 1 until layer L of CNN, for now set to 1 and 1 only\n",
    "strideMaxpool = np.array([8,4]) #stride from layer 1 until layer L of Maxpool, for now set to 8 and 4\n",
    "strideMaxF = np.array([8,4]) #F size for max pooling\n",
    "outputNumber = 6 #for now since we have 6 class\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = createPlaceholders(64, 64, 3, 6)\n",
    "    parameters = initializeParameters(parametersDims)\n",
    "    Z3 = forwardPropagation(X, parameters, strideCNN, strideMaxpool, strideMaxF, outputNumber)\n",
    "    cost = computeCost(Z3, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, {X: np.random.randn(4,64,64,3), Y: np.random.randn(4,6)})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, parametersDims, strideCNN, strideMaxpool, strideMaxF, learningRate = 0.009, epochNums = 100, minibatchSize = 64, printCost = True):\n",
    "    \"\"\"Implement a CNN neural network with this order:\n",
    "    CNN (repetition based on the number of parametersDims length)-> FC (regular NN ends with softmax)-> OUTPUT\n",
    "    \n",
    "    CNN sequence is as follows: Convolution -> ReLU -> Maxpool\n",
    "    \n",
    "    Input is as follows:\n",
    "    X_train = numpy array for train dataset, in shape of (m, nH0, nW0, nC0)\n",
    "    Y_train = numpy array for train result, in shape of (m, nY)\n",
    "    X_test = numpy array for test ddataset, in shape of (m, nH, nW, nC)\n",
    "    Y_test = numpy array for test result, in shape of (m, nY)\n",
    "    parametersDims = 2d array: each of the 1d array has (nH, nW,nC_prev, nC)\n",
    "    strideCNN = stride from layer 1 until layer L of CNN\n",
    "    strideMaxpool = stride from layer 1 until layer L of Maxpool\n",
    "    strideMaxF = f size for max pooling\n",
    "    learningRate = the rate for AdamOptimizer, set 0.009 as default\n",
    "    epochNums = for the number of rep, set 100 as default\n",
    "    minibatchSize = the number of m inside each minibatch, set 64 as default\n",
    "    printCost = print every 100 epochs\n",
    "    \n",
    "    Output:\n",
    "    trainAccuracy = accuracy for train in float\n",
    "    testAccuracy = accuracy for test in float\n",
    "    parameters = trained parameters based on shape parametersDims\"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, nH0, nW0, nC0) = X_train.shape             \n",
    "    nY = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    #CREATING THE PATH\n",
    "    #create placeholder\n",
    "    X, Y = createPlaceholders(nH0, nW0, nC0, nY)\n",
    "    #initialize parameters\n",
    "    parameters = initializeParameters(parametersDims)\n",
    "    #forward propagation\n",
    "    ZL = forwardPropagation(X,parameters, strideCNN, strideMaxpool, strideMaxF, nY)\n",
    "    #countingcost\n",
    "    cost = computeCost(ZL, Y)\n",
    "    #create the backprop\n",
    "    gradOptimizer = tf.train.AdamOptimizer(learning_rate = learningRate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    #create the session\n",
    "    with tf.Session() as sess:\n",
    "        #intialize everything\n",
    "        sess.run(init)\n",
    "        \n",
    "        #start the epoch\n",
    "        for epoch in range(epochNums):\n",
    "            #divide the minibatch first\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatchSize, seed)\n",
    "            epochCost = 0\n",
    "            for minibatch in minibatches:\n",
    "                minibatchX, minibatchY = minibatch\n",
    "                #run the session\n",
    "                trash, minibatchCost = sess.run(fetches = [gradOptimizer, cost], feed_dict = {X: minibatchX, Y:minibatchY})\n",
    "                \n",
    "                #add the cost to the minibatchCost\n",
    "                epochCost += minibatchCost\n",
    "            \n",
    "            #after done with everything, divide the epochCost with the total number of data\n",
    "            epochCost /= m\n",
    "            if printCost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epochCost))\n",
    "            if printCost == True and epoch % 10 == 0:\n",
    "                costs.append(epochCost)\n",
    "                \n",
    "        #Closing session, showing the plot\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.xlabel(\"Iteration every 10\")\n",
    "        plt.ylabel(\"Cost\")\n",
    "        plt.title(f\"CNN with learning rate = {learningRate}\")\n",
    "        plt.show()\n",
    "\n",
    "        #Calculate the correct number\n",
    "        predictFinal = tf.argmax(ZL, axis = 1) #Find the max one, since we are using softmax\n",
    "        correctPrediction = tf.equal(predictFinal, tf.argmax(Y,1)) #we use placeholder so that we can replace this with train/test set later\n",
    "\n",
    "        #Calculate test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correctPrediction, \"float\"))\n",
    "        trainAccuracy = accuracy.eval(feed_dict = {X:X_train, Y:Y_train})\n",
    "        testAccuracy = accuracy.eval(feed_dict = {X:X_test, Y:Y_test})\n",
    "        print(f\"Train Accuracy: {trainAccuracy}\")\n",
    "        print(f\"Test Accuracy: {testAccuracy}\")\n",
    "        \n",
    "        \"\"\"\n",
    "        #trying to count F1 score\n",
    "        f1Score = tf.contrib.metrics.f1_score(Y, ZL)\n",
    "        print(f1Score)\n",
    "        f1Train = f1Score.eval(feed_dict = {X:X_train, Y:Y_train})\n",
    "        f1Test = f1Score.eval(feed_dict = {X:X_test, Y:Y_test})\n",
    "        print(f\"F1 Score train: {f1Train}\")\n",
    "        print(f\"F1 Score test: {f1Test}\")\n",
    "        \"\"\"\n",
    "        return trainAccuracy, testAccuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027929562208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027929562208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027929562208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027929562208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A8A6588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A8A6588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A8A6588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002792A8A6588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Cost after epoch 0: 0.028464\n",
      "Cost after epoch 5: 0.028210\n",
      "Cost after epoch 10: 0.028212\n",
      "Cost after epoch 15: 0.028214\n",
      "Cost after epoch 20: 0.028176\n",
      "Cost after epoch 25: 0.026431\n",
      "Cost after epoch 30: 0.024904\n",
      "Cost after epoch 35: 0.023973\n",
      "Cost after epoch 40: 0.023674\n",
      "Cost after epoch 45: 0.023219\n",
      "Cost after epoch 50: 0.023020\n",
      "Cost after epoch 55: 0.022211\n",
      "Cost after epoch 60: 0.021387\n",
      "Cost after epoch 65: 0.018872\n",
      "Cost after epoch 70: 0.017532\n",
      "Cost after epoch 75: 0.016760\n",
      "Cost after epoch 80: 0.016186\n",
      "Cost after epoch 85: 0.015999\n",
      "Cost after epoch 90: 0.015367\n",
      "Cost after epoch 95: 0.014907\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6620370149612427\n",
      "Test Accuracy: 0.5916666388511658\n"
     ]
    }
   ],
   "source": [
    "parametersDims = [[4,4,3,8], [2,2,8,16]]\n",
    "strideCNN = [1,1] #stride from layer 1 until layer L of CNN, for now set to 1 and 1 only\n",
    "strideMaxpool = np.array([8,4]) #stride from layer 1 until layer L of Maxpool, for now set to 8 and 4\n",
    "strideMaxF = np.array([8,4]) #F size for max pooling\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test, parametersDims, strideCNN, strideMaxpool, strideMaxF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Xpredict, parameters, strideCNN, strideMaxpool, strideMaxF, nY):\n",
    "    \"\"\"use for predicting\n",
    "    \n",
    "    Input:\n",
    "    Xpredict = Use for predicting testcase, in shape of (1, nH, nW, nC)\n",
    "    parameters = trained parameters before\n",
    "    strideCNN = stride from layer 1 until layer L of CNN\n",
    "    strideMaxpool = stride from layer 1 until layer L of Maxpool\n",
    "    strideMaxF = f size for max pooling\n",
    "    nY = number of category for Y\n",
    "    \n",
    "    Output:\n",
    "    predictCategory = output the possibleCategory\n",
    "    \"\"\"\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    Xpredict = np.array([Xpredict])\n",
    "    (m, nH0, nW0, nC0) = Xpredict.shape\n",
    "    #Create Path\n",
    "    #Create placeholder\n",
    "    print(Xpredict.shape)\n",
    "    X, trash = createPlaceholders(nH0, nW0, nC0, nY)\n",
    "    #ForwardProp\n",
    "    ZL = forwardPropagation(X,parameters, strideCNN, strideMaxpool, strideMaxF, nY)\n",
    "    \n",
    "    finalY = tf.argmax(ZL, 1)\n",
    "    session.run(finalY)\n",
    "    return finalY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, 64, 64, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"W1:0\", shape=(4, 4, 3, 8), dtype=float32_ref) must be from the same graph as Tensor(\"X:0\", shape=(?, 64, 64, 3), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-28acfbbbd78a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstrideMaxF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#F size for max pooling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideMaxpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideMaxF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-68-e645b2b2b5ae>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(Xpredict, parameters, strideCNN, strideMaxpool, strideMaxF, nY)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreatePlaceholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnH0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnW0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnC0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#ForwardProp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mZL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforwardPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideMaxpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideMaxF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mfinalY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e2b1b33d0637>\u001b[0m in \u001b[0;36mforwardPropagation\u001b[1;34m(X, parameters, strideCNN, strideMaxpool, strideMaxF, outputNumber)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mstrideMaxF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstrideMaxpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"Z{i+1}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"P{i}\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"W{i+1}\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideCNN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideCNN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"A{i+1}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"Z{i+1}\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"P{i+1}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"A{i+1}\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrideMaxF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideMaxF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrideMaxpool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrideMaxpool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   1951\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1952\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1953\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   1954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1068\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m   1071\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    364\u001b[0m       \u001b[1;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m       \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   6133\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6134\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6135\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6136\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6137\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   6069\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6070\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" %\n\u001b[1;32m-> 6071\u001b[1;33m                      (item, original_item))\n\u001b[0m\u001b[0;32m   6072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"W1:0\", shape=(4, 4, 3, 8), dtype=float32_ref) must be from the same graph as Tensor(\"X:0\", shape=(?, 64, 64, 3), dtype=float32)."
     ]
    }
   ],
   "source": [
    "strideCNN = [1,1] #stride from layer 1 until layer L of CNN, for now set to 1 and 1 only\n",
    "strideMaxpool = np.array([8,4]) #stride from layer 1 until layer L of Maxpool, for now set to 8 and 4\n",
    "strideMaxF = np.array([8,4]) #F size for max pooling\n",
    "nY = Y_train.shape[1]\n",
    "parameters = predict(X_train[0], parameters, strideCNN, strideMaxpool, strideMaxF, nY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
